# -*- coding: utf-8 -*-
"""DecisionTreeExample.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1_OFKPR4wBudZl7h6ojzHLUm0O5otC7-7
"""

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns

df = pd.read_csv("car_evaluation.csv")
df.head()

df.shape

"""Kolon isimlerini düzeltelim"""

col_names = ['buying', 'maint', 'doors', 'persons', 'lug_boot', 'safety', 'class']

df.columns = col_names

df.head()

df.info()

for col in df.columns:
    print(df[col].value_counts())

"""Datanın dağılışına baktığımızda "class" dışında genel olarak balanced olduğunu söyleyebiliriz"""

df.isnull().sum()

"""Future engineering kısmına geçelim ve numerik/kategorik dataları belirleyelim"""

df["doors"].unique()

df["doors"] = df["doors"].replace("5more", 5)

df["doors"].unique()

df["doors"] = df["doors"].astype(int)

df["persons"].unique()

df["persons"] = df["persons"].replace("more", 5)

df["persons"].unique()

df["persons"] = df["persons"].astype(int)

df.info()

sns.scatterplot(x=df["buying"], y=df["maint"], hue=df["class"])
plt.show()

"""Değerler continuous olmadığı, çoğu kategorik olduğu için bu şekilde gözüküyor"""

sns.barplot(x=df["buying"], hue=df["class"])
plt.show()

sns.scatterplot(x=df["lug_boot"], y=df["safety"], hue=df["class"])
plt.show()

df.info()

X = df.drop("class", axis=1)
y = df["class"]

from sklearn.model_selection import train_test_split

X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=15)

X_train.shape

"""Ordinal Encoding kısmına geçiyoruz, bunu tercih etmemizin sebebi kademeli bir derecelendirme olması"""

from sklearn.preprocessing import OrdinalEncoder
from sklearn.compose import ColumnTransformer
from sklearn.pipeline import Pipeline

categorical_cols = ["buying", "maint", "lug_boot", "safety"]
numerical_cols = ["doors", "persons"]
ordinal_encoder = OrdinalEncoder(categories = [
    ["low", "med", "high", "vhigh"], #buying
    ["low", "med", "high", "vhigh"], #maint
    ["small", "med", "big"], #lug_boot
    ["low", "med", "high"] #safety
])

preprocessor = ColumnTransformer(
    transformers=[
        ("ordinal_encoder", ordinal_encoder, categorical_cols),
    ], remainder = "passthrough") # encode etmediklerimin yerinde kalması için gerekli

X_train_transformed = preprocessor.fit_transform(X_train)
X_test_transformed = preprocessor.transform(X_test)

for col in categorical_cols:
  print(df[col].value_counts())

pd.DataFrame(X_train_transformed)

"""Ağacı eğitme kısmına geçiyoruz"""

from sklearn.tree import DecisionTreeClassifier

tree_model = DecisionTreeClassifier(criterion="gini", max_depth=3, random_state=0)
tree_model.fit(X_train_transformed, y_train)

y_pred = tree_model.predict(X_test_transformed)

from sklearn.metrics import confusion_matrix, accuracy_score, classification_report

print(accuracy_score(y_test, y_pred))
print(confusion_matrix(y_test, y_pred))
print(classification_report(y_test, y_pred))

plt.figure(figsize=(12,8))

from sklearn import tree
column_names = categorical_cols + numerical_cols
tree.plot_tree(tree_model.fit(X_train_transformed, y_train), feature_names=column_names)

"""Şimdi hyperparameter tuning yaparak ağaçta nasıl değişiklikler olduğunu gözlemleyeceğiz"""

param = {
    "criterion": ["gini", "entropy", "log_loss"],
    "splitter" : ["best", "random"],
    "max_depth": [1, 2, 3, 4, 5, 15, None],
    "max_features": ["sqrt", "log2", None]
}

from sklearn.model_selection import GridSearchCV
grid = GridSearchCV(estimator=DecisionTreeClassifier(), param_grid=param, cv=5, scoring="accuracy")
grid.fit(X_train_transformed, y_train)

grid.best_params_

y_pred = grid.predict(X_test_transformed)

print(accuracy_score(y_test, y_pred))
print(confusion_matrix(y_test, y_pred))
print(classification_report(y_test, y_pred))

"""Dağılımların düzelip, accuracynin arttığını gözlemleyebiliyoruz"""

tree_model_new = DecisionTreeClassifier(criterion="entropy", max_depth=None, max_features=None, splitter="best")

tree_model_new.fit(X_train_transformed, y_train)
y_pred = tree_model_new.predict(X_test_transformed)
print(accuracy_score(y_test, y_pred))
print(confusion_matrix(y_test, y_pred))
print(classification_report(y_test, y_pred))

tree.plot_tree(tree_model_new.fit(X_train_transformed, y_train), feature_names=column_names)