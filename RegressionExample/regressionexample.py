# -*- coding: utf-8 -*-
"""RegressionExample.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1HlnKRG2zweJmltUbNseT1_u09lXCUvFU
"""

# Commented out IPython magic to ensure Python compatibility.
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
# %matplotlib inline

df = pd.read_csv('forest_fires.csv')

df.head()

df.columns

df.info()

"""Non-null satırların içinde null olan veriler var onları elememiz gerekiyor:"""

df.shape

df.shape

df.drop(122, inplace=True)

df.isnull().sum()

df[df.isnull().any(axis=1)]

df.loc[:123, "Region"] = 0
df.loc[123:, "Region"] = 1

df.head()

df.tail()

df.info()

df = df.dropna().reset_index(drop=True)

df.isnull().sum()

"""Region'un nerede tam değiştiğini gözlemleyelim:"""

df.iloc[121]

df.iloc[122]

"""Kolon isimlerinin başındaki böşlukları kaldıralım:"""

df.columns

df.columns = df.columns.str.strip()

df.columns

df.info()

"""Her şeyin object olmasına gerek yok çünkü veriler zaten genel olarak sayısal:"""

df["day"].unique()

df[df["day"] == "day"]

"""bölge değişikliğinde kolon başlıkları tekrarlandığı için bu satırın da kaldırılması lazım:"""

df.drop(122, inplace=True)

df[["day","month","year","Temperature","RH","Ws"]] = df[["day","month","year","Temperature","RH","Ws"]].astype(int)

df[["Rain","FFMC","DMC","DC","ISI","BUI","FWI"]] = df[["Rain","FFMC","DMC","DC","ISI","BUI","FWI"]].astype(float)

df.info()

df.describe()

df["Classes"].value_counts()

df["Classes"] = np.where(df["Classes"].str.strip().str.contains("not fire"), 0, 1)

df["Classes"].value_counts()

df["Classes"].value_counts(normalize=True)

sns.heatmap(df.corr())
plt.show()

"""Burada korelasyonu var gibi gözüken ama olmayan day month year gibi kolonlar var onları kaldıralım:"""

df.drop(["day","month","year"], axis=1, inplace=True)

df.head()

# dependent independent features
X = df.drop("FWI", axis=1)
y = df["FWI"]

df.head()

X

y

from sklearn.model_selection import train_test_split
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=15)

X_train.shape

X_train.corr()

"""İki independent feature birbirine çok yüksek korelasyonu varsa bilgi tekrarı gibi olmuş olur ve boşuna karmaşıklığı arttırır. Multicollinearity'e sebebiyet verebilir bu da overfitting ortaya çıkarabilir. Yüksek korelasyon konuya göre değişebilir ama biz varsayımsal olarak 80%, 90% olarak düşünebiliriz."""

# redundancy, multicollinearity, overfitting

X_train.corr().iloc[0,2]

"""Tüm tablodaki korelasyonları kıyaslayıp thresholddan büyük olanları belirleyecek bir fonksiyon yazalım:"""

def correlation_for_dropping(df, threshold):
  columns_to_drop = set()
  corr = df.corr()
  for i in range(len(corr.columns)):
    for j in range(i):
      if(abs(corr.iloc[i, j] > threshold)):
        columns_to_drop.add(corr.columns[i])
  return columns_to_drop

columns_drop = correlation_for_dropping(X_train, 0.85)

columns_drop

X_train.drop(columns_drop, axis=1, inplace=True)
X_test.drop(columns_drop, axis=1, inplace=True)

X_train.shape

X_test.shape

from sklearn.preprocessing import StandardScaler
scaler = StandardScaler()

X_train_scaled = scaler.fit_transform(X_train)
X_test_scaled = scaler.transform(X_test)

"""Görselleştirerek scaling işleminin nasıl bir etki oluşturduğunu gözlemleyelim:"""

plt.subplots(figsize=(15,5))
plt.subplot(1,2,1)
sns.boxplot(data=X_train)
plt.title("X_train")
plt.subplot(1,2,2)
sns.boxplot(data=X_train_scaled)
plt.title("X_train_scaled")
plt.show()

from sklearn.linear_model import LinearRegression
from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score

linear = LinearRegression()
linear.fit(X_train_scaled, y_train)
y_pred = linear.predict(X_test_scaled)
mae = mean_absolute_error(y_test, y_pred)
mse = mean_squared_error(y_test, y_pred)
score = r2_score(y_test, y_pred)
print("Mean Absolute Error: ", mae)
print("Mean Squared Error: ", mse)
print("R2 Score: ", score)
plt.scatter(y_test, y_pred)
plt.show()

from sklearn.linear_model import Ridge
from sklearn.linear_model import Lasso
from sklearn.linear_model import ElasticNet

lasso = Lasso()
lasso.fit(X_train_scaled, y_train)
y_pred = lasso.predict(X_test_scaled)
mae = mean_absolute_error(y_test, y_pred)
mse = mean_squared_error(y_test, y_pred)
score = r2_score(y_test, y_pred)
print("Mean Absolute Error: ", mae)
print("Mean Squared Error: ", mse)
print("R2 Score: ", score)
plt.scatter(y_test, y_pred)
plt.show()

ridge = Ridge()
ridge.fit(X_train_scaled, y_train)
y_pred = ridge.predict(X_test_scaled)
mae = mean_absolute_error(y_test, y_pred)
mse = mean_squared_error(y_test, y_pred)
score = r2_score(y_test, y_pred)
print("Mean Absolute Error: ", mae)
print("Mean Squared Error: ", mse)
print("R2 Score: ", score)
plt.scatter(y_test, y_pred)
plt.show()

elastic = ElasticNet()
elastic.fit(X_train_scaled, y_train)
y_pred = elastic.predict(X_test_scaled)
mae = mean_absolute_error(y_test, y_pred)
mse = mean_squared_error(y_test, y_pred)
score = r2_score(y_test, y_pred)
print("Mean Absolute Error: ", mae)
print("Mean Squared Error: ", mse)
print("R2 Score: ", score)
plt.scatter(y_test, y_pred)
plt.show()

"""Ridge ve Lasso kullanımının bu örnek için gerekli olmadığını söyleyebiliriz. Bu veri için en doğru seçenek linear regresyon gibi gözüküyor."""

# Lasso Cross Validation
from sklearn.linear_model import LassoCV
lassocv = LassoCV(cv=5)
lassocv.fit(X_train_scaled, y_train)
y_pred = lassocv.predict(X_test_scaled)
mae = mean_absolute_error(y_test, y_pred)
mse = mean_squared_error(y_test, y_pred)
score = r2_score(y_test, y_pred)
print("Mean Absolute Error: ", mae)
print("Mean Squared Error: ", mse)
print("R2 Score: ", score)
plt.scatter(y_test, y_pred)
plt.show()

"""ideal alpha:"""

lassocv.alpha_

"""tüm alphalar:"""

lassocv.alphas_

# Ridge Cross Validation
from sklearn.linear_model import RidgeCV
ridgecv = RidgeCV(cv=5)
ridgecv.fit(X_train_scaled, y_train)
y_pred = ridgecv.predict(X_test_scaled)
mae = mean_absolute_error(y_test, y_pred)
mse = mean_squared_error(y_test, y_pred)
score = r2_score(y_test, y_pred)
print("Mean Absolute Error: ", mae)
print("Mean Squared Error: ", mse)
print("R2 Score: ", score)
plt.scatter(y_test, y_pred)
plt.show()

# Elastic Net Cross Validation
from sklearn.linear_model import ElasticNetCV
elasticnetcv = ElasticNetCV(cv=5)
elasticnetcv.fit(X_train_scaled, y_train)
y_pred = elasticnetcv.predict(X_test_scaled)
mae = mean_absolute_error(y_test, y_pred)
mse = mean_squared_error(y_test, y_pred)
score = r2_score(y_test, y_pred)
print("Mean Absolute Error: ", mae)
print("Mean Squared Error: ", mse)
print("R2 Score: ", score)
plt.scatter(y_test, y_pred)
plt.show()
