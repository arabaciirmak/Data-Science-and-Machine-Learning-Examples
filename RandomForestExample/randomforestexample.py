# -*- coding: utf-8 -*-
"""RandomForestExample.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1dCqIrYRLfXxTkePHlXXUEx0JO2Nh_MT1
"""

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns

df = pd.read_csv("income_evaluation.csv")

df.head()

df.shape

df.columns

"""Kolon isimlerine baktığımızda anlaşılmaz ve yanlış formatta olanlar var onları düzeltelim"""

col_names = ["age", "workclass", "finalweight", "education", "education_num", "marital_status", "occupation", "relationship", "race", "sex", "capital_gain", "capital_loss", "hours_per_week", "native_counry", "income"]

df.columns = col_names

df.columns

df.rename(columns={"native_counry": "native_country"}, inplace=True)

df.info()

df.describe()

df.isnull().sum()

for col in df.columns:
  if df[col].dtype == "O":
    print(col)

"""Bu şekilde sadece kategorik olan değerleri görüntülemiş olduk, şimdi de bunları bir listeye atalım"""

categorical = [col for col in df.columns if df[col].dtype == "O"]
numerical = [col for col in df.columns if df[col].dtype != "O"]

categorical

numerical

df[categorical].head()

for col in categorical:
  print(df[col].value_counts())

df["income"].value_counts()

fig, ax = plt.subplots(figsize=(6, 5))
ax = sns.countplot(x="income", data=df, hue="sex")
ax.set_title("Income Distributionwith Gender")
plt.show()

fig, ax = plt.subplots(figsize=(6, 5))
ax = sns.countplot(x="income", data=df, hue="race")
ax.set_title("Income Distributionwith Race")
plt.show()

sns.catplot(y=df["hours_per_week"], hue=df["income"])
plt.show()

over_40_hours = df[df["hours_per_week"] > 40]
under_40_hours = df[df["hours_per_week"] <= 40]

over_40_hours["income"].value_counts()

under_40_hours["income"].value_counts()

categorical

df["workclass"].unique()

df["workclass"].value_counts()

df["workclass"] = df["workclass"].replace(" ?", np.nan)
df["workclass"].unique()

df["education"].unique()

df["marital_status"].unique()

df["occupation"].unique()

df["occupation"] = df["occupation"].replace(" ?", np.nan)
df["occupation"].unique()

df["sex"].unique()

df["race"].unique()

df["native_country"].unique()

df["native_country"] = df["native_country"].replace(" ?", np.nan)
df["native_country"].unique()

df.isnull().sum()

sns.pairplot(df, hue="income")
plt.show()

"""Encoding kısmına geçiyoruz"""

X = df.drop("income", axis=1)
y = df["income"]

from sklearn.model_selection import train_test_split
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=0)

categorical = [col for col in X_train.columns if X_train[col].dtype == "O"]

X_train[categorical].isnull().sum()

X_test[categorical].isnull().sum()

for i in [X_train, X_test]:
  i["workclass"] = i["workclass"].fillna(X_train["workclass"].mode()[0])
  i["occupation"] = i["occupation"].fillna(X_train["occupation"].mode()[0])
  i["native_country"] = i["native_country"].fillna(X_train["native_country"].mode()[0])

X_train[categorical].isnull().sum()

X_test[categorical].isnull().sum()

X_train[categorical].head()

df[categorical].nunique()

y_train_binary = y_train.apply(lambda x: 1 if x.strip() == ">50K" else 0)
target_means = y_train_binary.groupby(X_train["native_country"]).mean()

X_train["native_country_encoded"] = X_train["native_country"].map(target_means)
X_train["native_country_encoded"] = X_train["native_country_encoded"].fillna(y_train_binary.mean())
X_test["native_country_encoded"] = X_test["native_country"].map(target_means)
X_test["native_country_encoded"] = X_test["native_country_encoded"].fillna(y_train_binary.mean())

X_train.head()

X_train = X_train.drop("native_country", axis=1)
X_test = X_test.drop("native_country", axis=1)

categorical

one_hot_categories = [
 'workclass',
 'education',
 'marital_status',
 'occupation',
 'relationship',
 'race',
 'sex'
]

from sklearn.preprocessing import OneHotEncoder
from sklearn.compose import ColumnTransformer

encoder = ColumnTransformer(
    transformers=[
        ("cat", OneHotEncoder(handle_unknown="ignore"), one_hot_categories)
    ], remainder="passthrough"
)

X_train_enc = encoder.fit_transform(X_train)
X_test_enc = encoder.transform(X_test)

X_train_enc

columns = X_train.columns

columns

"""Model training kısmına geçiyoruz"""

from sklearn.ensemble import RandomForestClassifier

rfc = RandomForestClassifier(n_estimators=10, random_state=15)
rfc.fit(X_train_enc, y_train)

y_pred = rfc.predict(X_test_enc)

from sklearn.metrics import accuracy_score, classification_report, confusion_matrix

print(accuracy_score(y_test, y_pred))
print(confusion_matrix(y_test, y_pred))
print(classification_report(y_test, y_pred))

rfc = RandomForestClassifier(n_estimators=100, random_state=15)
rfc.fit(X_train_enc, y_train)
y_pred = rfc.predict(X_test_enc)
print(accuracy_score(y_test, y_pred))
print(confusion_matrix(y_test, y_pred))
print(classification_report(y_test, y_pred))

rfc.feature_importances_

feature_names = encoder.get_feature_names_out()
feature_scores = pd.Series(rfc.feature_importances_, index=feature_names).sort_values(ascending=False)

feature_scores

feature_scores.tail(10)

"""Bu çok da önemli olmayan kolonları atıp tekrar train test deneyelim"""

columns_to_drop = feature_scores.tail(10).index.tolist()
X_train_enc = pd.DataFrame(X_train_enc.toarray(), columns=feature_names)
X_train_enc = X_train_enc.drop(columns=columns_to_drop, axis=1)

columns_to_drop = feature_scores.tail(10).index.tolist()
X_test_enc = pd.DataFrame(X_test_enc.toarray(), columns=feature_names)
X_test_enc = X_test_enc.drop(columns=columns_to_drop, axis=1)

rfc = RandomForestClassifier(n_estimators=100, random_state=15)
rfc.fit(X_train_enc, y_train)
y_pred = rfc.predict(X_test_enc)
print(accuracy_score(y_test, y_pred))
print(confusion_matrix(y_test, y_pred))
print(classification_report(y_test, y_pred))

"""Çok büyük bir değişiklik olmadığını gözlemledik, kolon atmak yerine hyperparameter tuning denemek daha mantıklı olabilir

Hyperparameter Tuning
"""

rf_params = {
    "n_estimators": [100, 200, 500, 1000],
    "max_depth": [None, 5, 8, 10, 15],
    "max_features": ["sqrt", "log2", 5, 6, 7, 8],
    "min_samples_split": [2, 8, 15, 20]
}

from sklearn.model_selection import RandomizedSearchCV

rfc = RandomForestClassifier()
rscv = RandomizedSearchCV(estimator=rfc, param_distributions=rf_params, cv=3)
rscv.fit(X_train_enc, y_train)

y_pred = rscv.predict(X_test_enc)
print(accuracy_score(y_test, y_pred))
print(confusion_matrix(y_test, y_pred))
print(classification_report(y_test, y_pred))

"""Accuracyi 86% ye kadar çıkarmış olduk, başarılı bir sonuç

---


"""
